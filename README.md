# ü§ñ Hindemit AI - Next.js Chatbot

<div align="center">

[![Next.js](https://img.shields.io/badge/Next.js-16-black?style=for-the-badge&logo=next.js)](https://nextjs.org)
[![React](https://img.shields.io/badge/React-19-61DAFB?style=for-the-badge&logo=react)](https://react.dev)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-3178C6?style=for-the-badge&logo=typescript)](https://www.typescriptlang.org)
[![Vercel AI SDK](https://img.shields.io/badge/AI%20SDK-Vercel-000000?style=for-the-badge)](https://sdk.vercel.ai)

Ein moderner, vollst√§ndig funktionsf√§higer Chatbot mit Next.js, React und der Vercel AI SDK. Unterst√ºtzt mehrere AI-Modelle √ºber OpenRouter, Streaming Responses, intelligente Suggestions und ein RAG-System.

[Features](#-features) ‚Ä¢ [Installation](#-getting-started) ‚Ä¢ [Dokumentation](./LANDING.md) ‚Ä¢ [Tech Stack](#-tech-stack)

</div>

---

## üìã √úber das Projekt

**Hindemit AI** ist ein produktionsreifer Chatbot, der auf Next.js 16 (App Router), React 19 und TypeScript aufbaut. Der Chatbot nutzt die Vercel AI SDK in Kombination mit OpenRouter, um eine flexible und skalierbare L√∂sung f√ºr KI-gest√ºtzte Konversationen zu bieten.

Der Chatbot bietet eine vollst√§ndige Chat-Erfahrung mit Streaming Responses, intelligenten Suggestions, einem RAG-System zur Integration von Dokumenten und einer modernen, responsiven UI mit vielen Komponenten von shadcn-io.

### ‚ú® Was macht es besonders?

- üéØ **Flexible Model-Auswahl**: Wechsel zwischen verschiedenen AI-Modellen (Gemini, GPT, Grok) √ºber OpenRouter - ohne Code-√Ñnderungen
- ‚ö° **Streaming Responses**: Nahtlose, in Echtzeit generierte Antworten f√ºr eine fl√ºssige Benutzererfahrung
- üß† **Intelligente Suggestions**: Initiale und dynamisch generierte Folgefragen f√ºr bessere Interaktion
- üìö **RAG-System**: Integration von Dokumenten ohne externe Vector-Datenbank
- üé® **Moderne UI**: Professionelles Design mit shadcn-io Komponenten
- üìù **Markdown + LaTeX**: Vollst√§ndige Unterst√ºtzung f√ºr Code-Bl√∂cke, Mathematik und mehr

---

## üéØ Features

### üîÑ Flexible Model-Auswahl

Modelle k√∂nnen einfach und schnell √ºber OpenRouter-Anbindung getauscht werden. Unterst√ºtzt werden verschiedene Modelle wie:

- **Google Gemini 2.5 Flash** (Standard)
- **OpenAI GPT-5 Nano**
- **xAI Grok 4.1 Fast**

### ‚ö° Streaming Responses

Alle Chat-Antworten werden als Stream geliefert, was eine fl√ºssige Benutzererfahrung erm√∂glicht. Die Implementierung nutzt die `streamText` Funktion der Vercel AI SDK.

### üß† Intelligente Suggestions

- **Initial Suggestions**: Beim Start geladene Suggestions aus einer JSON-Datei
- **Dynamic Suggestions**: Automatisch generierte 3-5 relevante Folgefragen nach jeder Assistenten-Antwort

### üìö RAG-System (Retrieval-Augmented Generation)

Der Chatbot nutzt ein internes RAG-System, um relevante Informationen aus einer Knowledge Base zu laden und in die Konversation zu integrieren. Dies erm√∂glicht es dem Chatbot, auf spezifische Dokumente zu antworten, ohne externe Vector-Datenbanken zu ben√∂tigen.

**Wie es funktioniert:**

1.  **Dokumente hinzuf√ºgen**: Lege `.md`, `.txt`, `.pdf`, `.docx`, `.json` oder `.csv` Dateien in `src/data/knowledge-base/` ab.
2.  **Indexierung**: Beim ersten Start des Development Servers oder nach einem expliziten Re-Indexing werden diese Dokumente geparst, in kleinere "Chunks" unterteilt und als "Embeddings" (numerische Vektorrepr√§sentationen) in einem lokalen Vector Store gespeichert.
3.  **Suche**: Wenn ein Benutzer eine Frage stellt, wird diese Frage ebenfalls in ein Embedding umgewandelt. Das System sucht dann im Vector Store nach den relevantesten Dokument-Chunks (basierend auf der √Ñhnlichkeit der Embeddings).
4.  **Kontextintegration**: Die gefundenen relevanten Chunks werden zusammen mit dem System-Prompt an das AI-Modell gesendet, um eine pr√§zisere und kontextbezogenere Antwort zu generieren.

**Konfiguration:**

Die RAG-Konfiguration kann in [`src/lib/rag/config.ts`](src/lib/rag/config.ts) angepasst werden, einschlie√ülich des Pfads zur Knowledge Base, unterst√ºtzter Dateiformate, Chunk-Gr√∂√üen und √Ñhnlichkeitsschwellenwerte.

**Re-Indexing:**

Nachdem du Dokumente in `src/data/knowledge-base/` hinzugef√ºgt, ge√§ndert oder gel√∂scht hast, musst du ein Re-Indexing ausl√∂sen, damit die √Ñnderungen wirksam werden. Dies kann manuell √ºber den `/api/rag/reindex` API-Endpunkt erfolgen:

```bash
curl -X POST http://localhost:3000/api/rag/reindex
# Um ein vollst√§ndiges Re-Indexing zu erzwingen (l√∂scht und erstellt den Index neu):
curl -X POST -H "Content-Type: application/json" -d '{"force": true}' http://localhost:3000/api/rag/reindex
```

### üìù Markdown & Content Rendering

- **Markdown**: Vollst√§ndige Unterst√ºtzung mit GitHub Flavored Markdown
- **Syntax-Highlighting**: Code-Bl√∂cke mit Shiki
- **LaTeX/Math**: Mathematische Formeln mit KaTeX
- **Tabellen & Lists**: GFM Features f√ºr erweiterte Formatierung

### üé® Moderne UI

Viele Komponenten wurden von **shadcn-io** verwendet:

- Conversation-Komponenten f√ºr die Chat-Ansicht
- Message-Komponenten mit Avatar-Support
- Prompt-Input mit integrierter Toolbar
- Responsive Design f√ºr Desktop und Mobile

### üîÑ Real-time Chat-Interface

- Persistente Konversationshistorie w√§hrend der Session
- Auto-Scroll zu neuen Nachrichten
- Loading States mit visuellem Feedback
- Reset-Funktionalit√§t f√ºr neue Konversationen

---

## üõ† Tech Stack

### Frontend

- **[Next.js 16](https://nextjs.org)** - React Framework mit App Router
- **[React 19](https://react.dev)** - UI Library
- **[TypeScript](https://www.typescriptlang.org)** - Type Safety

### AI & Backend

- **[Vercel AI SDK](https://sdk.vercel.ai)** - AI Abstraktion (`@ai-sdk/react`, `ai`)
- **[OpenRouter](https://openrouter.ai)** - Flexible Model-Auswahl (`@openrouter/ai-sdk-provider`)

### UI & Styling

- **[Tailwind CSS](https://tailwindcss.com)** - Utility-First CSS Framework
- **[shadcn/ui](https://ui.shadcn.com)** - Viele Komponenten von shadcn-io
- **[Radix UI](https://www.radix-ui.com)** - Zug√§ngliche UI Primitives

### Markdown & Content

- **[react-markdown](https://github.com/remarkjs/react-markdown)** - Markdown Rendering
- **[Shiki](https://shiki.matsu.io)** - Syntax Highlighting
- **[KaTeX](https://katex.org)** - LaTeX Math Rendering

### Utilities

- **[nanoid](https://github.com/ai/nanoid)** - Unique ID Generation
- **[Motion](https://motion.dev)** - Animation Library

---

## üöÄ Getting Started

### Voraussetzungen

- **Node.js** 18+ oder 20+
- **npm**, **pnpm**, **yarn** oder **bun**
- **OpenRouter API Key** ([Hier anmelden](https://openrouter.ai))

### Installation

1. **Repository klonen**

   ```bash
   git clone https://github.com/yourusername/nextjs-chatbot.git
   cd nextjs-chatbot
   ```

2. **Abh√§ngigkeiten installieren**

   ```bash
   npm install
   # oder
   pnpm install
   # oder
   yarn install
   ```

3. **Umgebungsvariablen konfigurieren**

   Erstelle eine `.env.local` Datei im Root-Verzeichnis:

   ```env
   OPENROUTER_API_KEY=your_api_key_here
   ```

   > **Hinweis**: Erhalte deinen API Key auf [OpenRouter](https://openrouter.ai)

4. **Knowledge Base initialisieren (optional, aber empfohlen)**

   Beim ersten Start des Development Servers wird die Knowledge Base automatisch indiziert. Du kannst den Index auch manuell √ºber einen API-Endpunkt aktualisieren:

   ```bash
   curl -X POST http://localhost:3000/api/rag/reindex
   # Oder um ein vollst√§ndiges Re-Indexing zu erzwingen:
   curl -X POST -H "Content-Type: application/json" -d '{"force": true}' http://localhost:3000/api/rag/reindex
   ```

   > **Hinweis**: Das Re-Indexing ist notwendig, wenn du neue Dokumente hinzuf√ºgst, bestehende √§nderst oder l√∂schst.

5. **Development Server starten**

   ```bash
   npm run dev
   # oder
   pnpm dev
   # oder
   yarn dev
   ```

6. **√ñffne [http://localhost:3000](http://localhost:3000)** in deinem Browser

### Production Build

```bash
npm run build
npm start
```

---

## ‚öôÔ∏è Konfiguration

### Model-Auswahl anpassen

Die verf√ºgbaren AI-Modelle und der Standardmodell k√∂nnen in [`src/lib/constants.ts`](src/lib/constants.ts) angepasst werden. Die hier definierten Modelle werden im Dropdown des Chatbots angezeigt.

```typescript
export const MODELS: Model[] = [
  { id: "google/gemini-2.5-flash-lite", name: "Gemini 2.5 Flash" },
  { id: "openai/gpt-5-nano", name: "GPT-5 Nano" },
  { id: "x-ai/grok-4.1-fast", name: "Grok 4.1 Fast" },
  // F√ºge hier neue Modelle hinzu (siehe OpenRouter-Dokumentation f√ºr IDs)
];

export const DEFAULT_MODEL_ID = MODELS[0].id;
```

### System-Prompts anpassen

Die Verhaltensweisen des Chatbots k√∂nnen √ºber System-Prompts gesteuert werden:

- **Haupt-System-Prompt**: [`src/data/system-messages/system-prompt.txt`](src/data/system-messages/system-prompt.txt)
- **Suggestion-Prompt**: [`src/data/system-messages/suggestion-prompt.txt`](src/data/system-messages/suggestion-prompt.txt)

### Dokumente f√ºr RAG hinzuf√ºgen

F√ºge `.md`, `.txt`, `.pdf`, `.docx`, `.json` oder `.csv` Dateien zu [`src/data/knowledge-base/`](src/data/knowledge-base/) hinzu. Diese Dokumente werden automatisch vom RAG-System indiziert (nach einem Re-Indexing).

**Beispiel:**

```
src/data/knowledge-base/
‚îú‚îÄ‚îÄ company-data.md
‚îú‚îÄ‚îÄ customer-policies.md
‚îú‚îÄ‚îÄ new-product-docs.md      # Neu hinzuf√ºgen
‚îî‚îÄ‚îÄ support-faq.txt          # Neu hinzuf√ºgen
```

### Initiale Suggestions anpassen

Die initialen Gespr√§chsvorschl√§ge, die beim Start des Chatbots angezeigt werden, k√∂nnen in [`src/data/system-messages/initial-information.ts`](src/data/system-messages/initial-information.ts) angepasst werden:

```typescript
export const INITIAL_SUGGESTIONS = [
  "Wie kannst du mir helfen?",
  "Was sind deine Funktionen?",
  "Erz√§hle mir mehr √ºber dich.",
];
```

### RAG-System Konfiguration

Erweiterte Einstellungen f√ºr das RAG-System (Chunking, Embedding, √Ñhnlichkeitsschwellenwert etc.) findest du in [`src/lib/rag/config.ts`](src/lib/rag/config.ts):

```typescript
export const RAG_CONFIG = {
  knowledgeBasePath: join(process.cwd(), "src", "data", "knowledge-base"),
  supportedFormats: [".pdf", ".docx", ".txt", ".md", ".json", ".csv"],
  chunkTokens: 256, // Maximale Token pro Chunk
  chunkOverlapTokens: 32, // √úberlappung zwischen Chunks
  topK: 5, // Anzahl der Top-Chunks, die f√ºr den Kontext geladen werden
  minSimilarity: 0.3, // Minimale Kosinus-√Ñhnlichkeit f√ºr relevante Chunks
  // ... weitere Einstellungen
};
```

---

## üìÅ Projektstruktur

```
nextjs-chatbot/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/                    # Next.js App Router
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                # API Routes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat/           # Chat Completion Endpoint
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ suggestions/    # Dynamic & Initial Suggestions Endpoint
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag/reindex/    # RAG Re-Indexing Endpoint
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx
‚îÇ   ‚îú‚îÄ‚îÄ components/             # React Components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chatbot/            # Chatbot Components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                 # UI Components (shadcn-io)
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                  # Custom React Hooks
‚îÇ   ‚îú‚îÄ‚îÄ lib/                    # Utilities & Helpers
‚îÇ   ‚îî‚îÄ‚îÄ data/                   # Data Files
‚îÇ       ‚îú‚îÄ‚îÄ knowledge-base/     # Knowledge Base Documents
‚îÇ       ‚îî‚îÄ‚îÄ system-messages/    # Prompts & Initial Suggestions
‚îú‚îÄ‚îÄ public/                     # Static Assets
‚îú‚îÄ‚îÄ LANDING.md                  # Detaillierte Dokumentation
‚îî‚îÄ‚îÄ README.md                   # Diese Datei
```

> üìñ F√ºr eine detaillierte Beschreibung der Architektur siehe [LANDING.md](./LANDING.md)

---

## üíª Verwendung

Dieser Chatbot ist auf einfache Integration und Erweiterbarkeit ausgelegt. Hier sind die grundlegenden Interaktionen und Anpassungsm√∂glichkeiten f√ºr Entwickler.

### Quick-Start f√ºr Entwickler

1.  **Klonen & Installieren**: Hol dir das Projekt und installiere die Abh√§ngigkeiten.
    ```bash
    git clone https://github.com/yourusername/nextjs-chatbot.git
    cd nextjs-chatbot
    pnpm install # oder npm install / yarn install
    ```
2.  **API Key**: F√ºge deinen `OPENROUTER_API_KEY` in `.env.local` ein.
3.  **Starten**: Starte den Development Server.
    ```bash
    pnpm dev # oder npm run dev / yarn dev
    ```
4.  **Anpassen**: Bearbeite [`src/lib/constants.ts`](src/lib/constants.ts) f√ºr Modelle, [`src/data/system-messages/system-prompt.txt`](src/data/system-messages/system-prompt.txt) f√ºr Prompts und [`src/data/knowledge-base/`](src/data/knowledge-base/) f√ºr eigene Dokumente.

### Basis-Interaktion

1.  **Nachricht eingeben**: Tippe deine Frage in das Eingabefeld.
2.  **Model ausw√§hlen**: W√§hle ein AI-Modell aus dem Dropdown (optional, konfiguriert in [`src/lib/constants.ts`](src/lib/constants.ts)).
3.  **Absenden**: Klicke auf den Submit-Button oder dr√ºcke Enter.
4.  **Antwort erhalten**: Sieh zu, wie die Antwort in Echtzeit gestreamt wird.

### Suggestions nutzen

- **Initial Suggestions**: Klicke auf eine der vorgeschlagenen Fragen beim Start (konfiguriert in [`src/data/system-messages/initial-information.ts`](src/data/system-messages/initial-information.ts)).
- **Dynamic Suggestions**: Nach jeder Assistenten-Antwort werden relevante Folgefragen angezeigt (generiert √ºber `/api/suggestions`).

### Konversation zur√ºcksetzen

Klicke auf den **Reset**-Button im Header, um die Konversation zu l√∂schen und neu zu starten.

### Troubleshooting

- **`OPENROUTER_API_KEY is not set`**: Stelle sicher, dass `OPENROUTER_API_KEY` in deiner `.env.local` Datei korrekt gesetzt ist.
- **RAG-Probleme (Dokumente werden nicht gefunden)**: F√ºhre ein manuelles Re-Indexing √ºber `curl -X POST http://localhost:3000/api/rag/reindex` aus, nachdem du Dokumente hinzugef√ºgt oder ge√§ndert hast.
- **Modell reagiert nicht**: √úberpr√ºfe deine Internetverbindung und stelle sicher, dass das ausgew√§hlte Modell auf OpenRouter verf√ºgbar ist.

---

## üìö Weitere Dokumentation

F√ºr detaillierte technische Dokumentation, Architektur-√úbersicht, API-Dokumentation und Entwickler-Informationen siehe:

**[üìñ LANDING.md](./LANDING.md)** - Vollst√§ndige technische Dokumentation

Die LANDING.md enth√§lt:

- Detaillierte Architektur-Beschreibung
- Komplette API-Dokumentation
- Komponenten-Dokumentation
- Hooks & Utilities
- Erweiterungsm√∂glichkeiten
- Best Practices

---

## ü§ù Contributing

Beitr√§ge sind willkommen! Hier sind einige M√∂glichkeiten, wie du helfen kannst:

### Issues melden

1. Pr√ºfe, ob das Issue bereits existiert
2. Erstelle ein neues Issue mit:
   - Klarer Beschreibung des Problems
   - Steps to Reproduce
   - Erwartetes Verhalten
   - Screenshots (falls relevant)

### Pull Requests

1. **Fork** das Repository
2. Erstelle einen **Feature Branch** (`git checkout -b feature/AmazingFeature`)
3. **Commit** deine √Ñnderungen (`git commit -m 'Add some AmazingFeature'`)
4. **Push** zum Branch (`git push origin feature/AmazingFeature`)
5. √ñffne einen **Pull Request**

### Code-Standards

- Verwende TypeScript f√ºr alle neuen Dateien
- Folge den bestehenden Code-Konventionen
- Teste deine √Ñnderungen lokal
- Aktualisiere die Dokumentation wenn n√∂tig

---

## üìù License

Dieses Projekt ist unter der MIT License lizenziert - siehe die [LICENSE](LICENSE) Datei f√ºr Details.

---

## üîó Links & Ressourcen

- **Repository**: [GitHub](https://github.com/yourusername/nextjs-chatbot)
- **Issues**: [GitHub Issues](https://github.com/yourusername/nextjs-chatbot/issues)
- **OpenRouter**: [OpenRouter.ai](https://openrouter.ai)
- **Vercel AI SDK**: [sdk.vercel.ai](https://sdk.vercel.ai)
- **Next.js Dokumentation**: [nextjs.org/docs](https://nextjs.org/docs)
- **shadcn/ui**: [ui.shadcn.com](https://ui.shadcn.com)

---

## üôè Danksagungen

- [Vercel](https://vercel.com) f√ºr das AI SDK
- [OpenRouter](https://openrouter.ai) f√ºr die flexible Model-Auswahl
- [shadcn](https://twitter.com/shadcn) f√ºr die gro√üartigen UI-Komponenten
- Alle Contributors und Nutzer des Projekts

---

<div align="center">

**Made with ‚ù§Ô∏è using Next.js, React, and TypeScript**

‚≠ê Star dieses Repository wenn es dir hilft!

</div>
